{"ast":null,"code":"import _slicedToArray from \"/Users/albert/projects/med-bakery-react/client/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"/Users/albert/projects/med-bakery-react/client/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _regeneratorRuntime from \"/Users/albert/projects/med-bakery-react/client/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/albert/projects/med-bakery-react/client/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { encode, instantiate } from 'media-encoder-host';\nimport { addRecorderAudioWorkletModule, createRecorderAudioWorkletNode } from 'recorder-audio-worklet';\nimport { AudioBuffer, AudioBufferSourceNode, AudioWorkletNode, MediaStreamAudioSourceNode, MinimalAudioContext, addAudioWorkletModule } from 'standardized-audio-context';\nvar ERROR_MESSAGE = 'Missing AudioWorklet support. Maybe this is not running in a secure context.'; // @todo This should live in a separate file.\n\nvar createPromisedAudioNodesEncoderIdAndPort = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(audioBuffer, audioContext, channelCount, mediaStream, mimeType) {\n    var _yield$instantiate, encoderId, port, audioBufferSourceNode, mediaStreamAudioSourceNode, recorderAudioWorkletNode;\n\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _context.next = 2;\n            return instantiate(mimeType, audioContext.sampleRate);\n\n          case 2:\n            _yield$instantiate = _context.sent;\n            encoderId = _yield$instantiate.encoderId;\n            port = _yield$instantiate.port;\n\n            if (!(AudioWorkletNode === undefined)) {\n              _context.next = 7;\n              break;\n            }\n\n            throw new Error(ERROR_MESSAGE);\n\n          case 7:\n            audioBufferSourceNode = new AudioBufferSourceNode(audioContext, {\n              buffer: audioBuffer\n            });\n            mediaStreamAudioSourceNode = new MediaStreamAudioSourceNode(audioContext, {\n              mediaStream: mediaStream\n            });\n            recorderAudioWorkletNode = createRecorderAudioWorkletNode(AudioWorkletNode, audioContext, {\n              channelCount: channelCount\n            });\n            return _context.abrupt(\"return\", {\n              audioBufferSourceNode: audioBufferSourceNode,\n              encoderId: encoderId,\n              mediaStreamAudioSourceNode: mediaStreamAudioSourceNode,\n              port: port,\n              recorderAudioWorkletNode: recorderAudioWorkletNode\n            });\n\n          case 11:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function createPromisedAudioNodesEncoderIdAndPort(_x, _x2, _x3, _x4, _x5) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nexport var createWebAudioMediaRecorderFactory = function createWebAudioMediaRecorderFactory(createBlobEvent, createInvalidModificationError, createInvalidStateError, createNotSupportedError) {\n  return function (eventTarget, mediaStream, mimeType) {\n    var _a;\n\n    var sampleRate = (_a = mediaStream.getAudioTracks()[0]) === null || _a === void 0 ? void 0 : _a.getSettings().sampleRate;\n    var audioContext = new MinimalAudioContext({\n      latencyHint: 'playback',\n      sampleRate: sampleRate\n    });\n    var length = Math.max(1024, Math.ceil(audioContext.baseLatency * audioContext.sampleRate));\n    var audioBuffer = new AudioBuffer({\n      length: length,\n      sampleRate: audioContext.sampleRate\n    });\n    var bufferedArrayBuffers = [];\n    var promisedAudioWorkletModule = addRecorderAudioWorkletModule(function (url) {\n      if (addAudioWorkletModule === undefined) {\n        throw new Error(ERROR_MESSAGE);\n      }\n\n      return addAudioWorkletModule(audioContext, url);\n    });\n    var abortRecording = null;\n    var intervalId = null;\n    var promisedAudioNodesAndEncoderId = null;\n    var promisedPartialRecording = null;\n    var isAudioContextRunning = true;\n\n    var dispatchDataAvailableEvent = function dispatchDataAvailableEvent(arrayBuffers) {\n      eventTarget.dispatchEvent(createBlobEvent('dataavailable', {\n        data: new Blob(arrayBuffers, {\n          type: mimeType\n        })\n      }));\n    };\n\n    var requestNextPartialRecording = /*#__PURE__*/function () {\n      var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(encoderId, timeslice) {\n        var arrayBuffers;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.next = 2;\n                return encode(encoderId, timeslice);\n\n              case 2:\n                arrayBuffers = _context2.sent;\n\n                if (promisedAudioNodesAndEncoderId === null) {\n                  bufferedArrayBuffers.push.apply(bufferedArrayBuffers, _toConsumableArray(arrayBuffers));\n                } else {\n                  dispatchDataAvailableEvent(arrayBuffers);\n                  promisedPartialRecording = requestNextPartialRecording(encoderId, timeslice);\n                }\n\n              case 4:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2);\n      }));\n\n      return function requestNextPartialRecording(_x6, _x7) {\n        return _ref2.apply(this, arguments);\n      };\n    }();\n\n    var _resume = function resume() {\n      isAudioContextRunning = true;\n      return audioContext.resume();\n    };\n\n    var stop = function stop() {\n      if (promisedAudioNodesAndEncoderId === null) {\n        return;\n      }\n\n      if (abortRecording !== null) {\n        mediaStream.removeEventListener('addtrack', abortRecording);\n        mediaStream.removeEventListener('removetrack', abortRecording);\n      }\n\n      if (intervalId !== null) {\n        clearTimeout(intervalId);\n      }\n\n      promisedAudioNodesAndEncoderId.then( /*#__PURE__*/function () {\n        var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(_ref3) {\n          var encoderId, mediaStreamAudioSourceNode, recorderAudioWorkletNode, arrayBuffers;\n          return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n            while (1) {\n              switch (_context3.prev = _context3.next) {\n                case 0:\n                  encoderId = _ref3.encoderId, mediaStreamAudioSourceNode = _ref3.mediaStreamAudioSourceNode, recorderAudioWorkletNode = _ref3.recorderAudioWorkletNode;\n\n                  if (promisedPartialRecording !== null) {\n                    promisedPartialRecording.catch(function () {\n                      /* @todo Only catch the errors caused by a duplicate call to encode. */\n                    });\n                    promisedPartialRecording = null;\n                  }\n\n                  _context3.next = 4;\n                  return recorderAudioWorkletNode.stop();\n\n                case 4:\n                  mediaStreamAudioSourceNode.disconnect(recorderAudioWorkletNode);\n                  _context3.next = 7;\n                  return encode(encoderId, null);\n\n                case 7:\n                  arrayBuffers = _context3.sent;\n\n                  if (!(promisedAudioNodesAndEncoderId === null)) {\n                    _context3.next = 11;\n                    break;\n                  }\n\n                  _context3.next = 11;\n                  return suspend();\n\n                case 11:\n                  dispatchDataAvailableEvent([].concat(bufferedArrayBuffers, _toConsumableArray(arrayBuffers)));\n                  bufferedArrayBuffers.length = 0;\n                  eventTarget.dispatchEvent(new Event('stop'));\n\n                case 14:\n                case \"end\":\n                  return _context3.stop();\n              }\n            }\n          }, _callee3);\n        }));\n\n        return function (_x8) {\n          return _ref4.apply(this, arguments);\n        };\n      }());\n      promisedAudioNodesAndEncoderId = null;\n    };\n\n    var suspend = function suspend() {\n      isAudioContextRunning = false;\n      return audioContext.suspend();\n    };\n\n    suspend();\n    return {\n      get mimeType() {\n        return mimeType;\n      },\n\n      get state() {\n        return promisedAudioNodesAndEncoderId === null ? 'inactive' : isAudioContextRunning ? 'recording' : 'paused';\n      },\n\n      pause: function pause() {\n        if (promisedAudioNodesAndEncoderId === null) {\n          throw createInvalidStateError();\n        }\n\n        if (isAudioContextRunning) {\n          suspend();\n          eventTarget.dispatchEvent(new Event('pause'));\n        }\n      },\n      resume: function resume() {\n        if (promisedAudioNodesAndEncoderId === null) {\n          throw createInvalidStateError();\n        }\n\n        if (!isAudioContextRunning) {\n          _resume();\n\n          eventTarget.dispatchEvent(new Event('resume'));\n        }\n      },\n      start: function start(timeslice) {\n        var _a;\n\n        if (promisedAudioNodesAndEncoderId !== null) {\n          throw createInvalidStateError();\n        }\n\n        if (mediaStream.getVideoTracks().length > 0) {\n          throw createNotSupportedError();\n        }\n\n        eventTarget.dispatchEvent(new Event('start'));\n        var audioTracks = mediaStream.getAudioTracks(); // @todo TypeScript v4.4.2 removed the channelCount property from the MediaTrackSettings interface.\n\n        var channelCount = audioTracks.length === 0 ? 2 : (_a = audioTracks[0].getSettings().channelCount) !== null && _a !== void 0 ? _a : 2;\n        promisedAudioNodesAndEncoderId = Promise.all([_resume(), promisedAudioWorkletModule.then(function () {\n          return createPromisedAudioNodesEncoderIdAndPort(audioBuffer, audioContext, channelCount, mediaStream, mimeType);\n        })]).then( /*#__PURE__*/function () {\n          var _ref6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(_ref5) {\n            var _ref7, _ref7$, audioBufferSourceNode, encoderId, mediaStreamAudioSourceNode, port, recorderAudioWorkletNode;\n\n            return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n              while (1) {\n                switch (_context4.prev = _context4.next) {\n                  case 0:\n                    _ref7 = _slicedToArray(_ref5, 2), _ref7$ = _ref7[1], audioBufferSourceNode = _ref7$.audioBufferSourceNode, encoderId = _ref7$.encoderId, mediaStreamAudioSourceNode = _ref7$.mediaStreamAudioSourceNode, port = _ref7$.port, recorderAudioWorkletNode = _ref7$.recorderAudioWorkletNode;\n                    mediaStreamAudioSourceNode.connect(recorderAudioWorkletNode);\n                    _context4.next = 4;\n                    return new Promise(function (resolve) {\n                      audioBufferSourceNode.onended = resolve;\n                      audioBufferSourceNode.connect(recorderAudioWorkletNode);\n                      audioBufferSourceNode.start(audioContext.currentTime + length / audioContext.sampleRate);\n                    });\n\n                  case 4:\n                    audioBufferSourceNode.disconnect(recorderAudioWorkletNode);\n                    _context4.next = 7;\n                    return recorderAudioWorkletNode.record(port);\n\n                  case 7:\n                    if (timeslice !== undefined) {\n                      promisedPartialRecording = requestNextPartialRecording(encoderId, timeslice);\n                    }\n\n                    return _context4.abrupt(\"return\", {\n                      encoderId: encoderId,\n                      mediaStreamAudioSourceNode: mediaStreamAudioSourceNode,\n                      recorderAudioWorkletNode: recorderAudioWorkletNode\n                    });\n\n                  case 9:\n                  case \"end\":\n                    return _context4.stop();\n                }\n              }\n            }, _callee4);\n          }));\n\n          return function (_x9) {\n            return _ref6.apply(this, arguments);\n          };\n        }());\n        var tracks = mediaStream.getTracks();\n\n        abortRecording = function abortRecording() {\n          stop();\n          eventTarget.dispatchEvent(new ErrorEvent('error', {\n            error: createInvalidModificationError()\n          }));\n        };\n\n        mediaStream.addEventListener('addtrack', abortRecording);\n        mediaStream.addEventListener('removetrack', abortRecording);\n        intervalId = setInterval(function () {\n          var currentTracks = mediaStream.getTracks();\n\n          if ((currentTracks.length !== tracks.length || currentTracks.some(function (track, index) {\n            return track !== tracks[index];\n          })) && abortRecording !== null) {\n            abortRecording();\n          }\n        }, 1000);\n      },\n      stop: stop\n    };\n  };\n};","map":null,"metadata":{},"sourceType":"module"}